# Natural Language Processing

## [Mini Project -1 ](https://github.com/gaurav2139/NLP-in-Tensorflow/tree/master/Mini%20Project%20-1)
## [Mini Project -2 ](https://github.com/gaurav2139/NLP-in-Tensorflow/tree/master/Mini%20Project%20-2)
### [LOR Chunks output](https://github.com/gaurav2139/NLP-in-Tensorflow/tree/master/Chunks_output)

* Mini Project - 2
  - Count_vecorization.ipynb
    - This file consists of Sentimental Analysis (also includes embedding and vertorizatiotion) done in the lecuture 
  - Exploratory_Text_Analysis.ipynb
    - Mini Project done by Analysing data from the reviews of the customer that buy Amazon prodcuts
  - Regex_Chunk.ipynb
    - Using grammar rule and breaking the file data into chunks
  - Stanford_NLP.ipynb
    - Performing NLP pipeline on regional lanugage, here in the document it's Hindi.
  - Task.ipynb
    - Performing bigrams on the data
  - Text_classification_Naive_Bayes.ipynb
    - Another mini project, where text classification is done based on Naive Bayes from Scikit-learn
  - lor1 .ipynb
    - Given letter of recommendation, we need to draw out chunks from using the grammar defined
  - lor2.ipynb
    - Similar to above, only the LOR changes
  - web_scrap.ipynb
    - Scrapped data from the internet and drew chunks of the scrapped data, also the data is visulaized using displacy

* Mini Project - 1
  - hw1.py
    - NLP tasks such as Stemming (used many stemming methods) and Lemmatization are done on the Gutenberg corpus
  - hw2.py
    - Performed Stemming, Lemmatization and other NLP tasks from CMU dataset and also finding the COSINE similarity for the documents
  - POS_TAG.py
    - Parrts of speech tagging for the data and also how the acutal worklow works can be found in this file
  - NLTK.ipynb
    - Stemming, Lemmatization and Tokenization
  - Pract1.ipynb
    - Emebedding the data and performing vectorization, done using Keras API
  
